{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ad0838f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import kagglehub\n",
    "\n",
    "# Download latest version\n",
    "path = kagglehub.dataset_download(\"ellipticco/elliptic-data-set\")\n",
    "\n",
    "print(\"Path to dataset files:\", path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c96e8c77",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df_edges = pd.read_csv('~/.cache/kagglehub/datasets/ellipticco/elliptic-data-set/versions/1/elliptic_bitcoin_dataset/elliptic_txs_edgelist.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adb5daff",
   "metadata": {},
   "outputs": [],
   "source": [
    "#node indices need to be integers i such that 0<=i<num_nodes\n",
    "\n",
    "num_seen = 0\n",
    "\n",
    "node_dic = {}\n",
    "\n",
    "for row in df_edges.values:\n",
    "    \n",
    "    for node in row:\n",
    "        \n",
    "        if node not in node_dic.keys():\n",
    "            \n",
    "            node_dic[node] = num_seen\n",
    "            \n",
    "            num_seen += 1\n",
    "            \n",
    "node_dic_inv = {node_dic[node]:node for node in node_dic.keys()}\n",
    "\n",
    "sorted_keys = sorted(node_dic_inv.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f0e66cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "sources = torch.from_numpy(np.array([node_dic[source] for source in df_edges['txId1'].values]))\n",
    "\n",
    "targets = torch.from_numpy(np.array([node_dic[target] for target in df_edges['txId2'].values]))\n",
    "\n",
    "edge_index = torch.stack([sources,targets])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5230f3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_features = pd.read_csv('~/.cache/kagglehub/datasets/ellipticco/elliptic-data-set/versions/1/elliptic_bitcoin_dataset/elliptic_txs_features.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cb7684c",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_nodes = len(df_features) + 1 #no row for first node; column names are first node's features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b427dbe0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#column names are first node's features\n",
    "\n",
    "first_node = np.float64(df_features.columns[0])\n",
    "\n",
    "first_node_features = np.array([np.float64(col) for col in df_features.columns[1:]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7238b632",
   "metadata": {},
   "outputs": [],
   "source": [
    "#node features need to be ordered by node index\n",
    "\n",
    "features_dic = {first_node:first_node_features}\n",
    "\n",
    "for row in df_features.values:\n",
    "    \n",
    "    if row[0] not in features_dic.keys():\n",
    "        \n",
    "        features_dic[row[0]] = row[1:]\n",
    "        \n",
    "features = np.array([features_dic[node_dic_inv[key]] for key in sorted_keys])\n",
    "\n",
    "x = torch.tensor(features, dtype = torch.float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8218d74e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_classes = pd.read_csv('~/.cache/kagglehub/datasets/ellipticco/elliptic-data-set/versions/1/elliptic_bitcoin_dataset/elliptic_txs_classes.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de9433d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#class labels need to be in range(num_classes); will not train to predict 'unknown' label\n",
    "\n",
    "class_map = {'1':1, '2':0, 'unknown':3}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac06b39e",
   "metadata": {},
   "outputs": [],
   "source": [
    "classes_dic = {}\n",
    "\n",
    "for row in df_classes.values:\n",
    "    \n",
    "    classes_dic[row[0]] = class_map[row[1]]\n",
    "    \n",
    "y = torch.tensor(np.array([classes_dic[node_dic_inv[key]] for key in sorted_keys]), dtype = torch.long)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6491db9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "val_split = math.floor(num_nodes*.75)\n",
    "\n",
    "i, j = val_split, val_split\n",
    "\n",
    "time_block = features[i][0]\n",
    "\n",
    "while min([features[k][0] == time_block for k in [i,j]]):\n",
    "    \n",
    "    i -= 1\n",
    "    \n",
    "    j += 1\n",
    "\n",
    "if features[i][0] != time_block:\n",
    "    \n",
    "    val_split = i + 1\n",
    "        \n",
    "else:\n",
    "    \n",
    "    val_split = j\n",
    "    \n",
    "val_time_block = features[val_split][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01c5311e",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_split = math.floor(num_nodes*.85)\n",
    "\n",
    "i, j = test_split, test_split\n",
    "\n",
    "time_block = features[i][0]\n",
    "\n",
    "while min([features[k][0] == time_block for k in [i,j]]):\n",
    "    \n",
    "    i -= 1\n",
    "    \n",
    "    j += 1\n",
    "    \n",
    "if features[i][0] != time_block:\n",
    "    \n",
    "    test_split = i + 1\n",
    "        \n",
    "else:\n",
    "    \n",
    "    test_split = j\n",
    "    \n",
    "test_time_block = features[test_split][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6ae68c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_mask = torch.tensor(np.array([i < val_split for i in range(num_nodes)]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cdeb4ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_mask = torch.tensor(np.array([val_split <= i and i < test_split  for i in range(num_nodes)]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa562a08",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_mask = torch.tensor(np.array([test_split <= i  for i in range(num_nodes)]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0d9f83d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch_geometric.data import Data\n",
    "\n",
    "data = Data(x = x, edge_index = edge_index, y = y, train_mask = train_mask, val_mask = val_mask, test_mask = test_mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de1d19d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as F\n",
    "from torch_geometric.nn import GCNConv\n",
    "\n",
    "class GCN(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.conv1 = GCNConv(data.num_node_features, 16)\n",
    "        self.conv2 = GCNConv(16, 1)\n",
    "\n",
    "    def forward(self, data):\n",
    "        x, edge_index = data.x, data.edge_index\n",
    "\n",
    "        x = self.conv1(x, edge_index)\n",
    "        x = F.relu(x)\n",
    "        x = F.dropout(x, training=self.training)\n",
    "        x = self.conv2(x, edge_index)\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7922c19b",
   "metadata": {},
   "outputs": [],
   "source": [
    "known_mask = y != 3 #so nodes n such that the licitness of n is uncertain may be filtered out prior to calculating loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c461c96",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_known_mask = torch.logical_and(train_mask, known_mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95820971",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_known_mask = torch.logical_and(train_mask, known_mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a039b6d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_test_nodes = test_known_mask.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "674fb748",
   "metadata": {},
   "outputs": [],
   "source": [
    "class WeightedFocalLoss(torch.nn.Module):\n",
    "    \"Non weighted version of Focal Loss\"\n",
    "    def __init__(self, alpha=.25, gamma=2):\n",
    "        super(WeightedFocalLoss, self).__init__()\n",
    "        self.alpha = torch.tensor([alpha, 1-alpha])\n",
    "        self.gamma = gamma\n",
    "\n",
    "    def forward(self, inputs, targets):\n",
    "        BCE_loss = F.binary_cross_entropy_with_logits(inputs, targets, reduction='none')\n",
    "        targets = targets.type(torch.long)\n",
    "        at = self.alpha.gather(0, targets.data.view(-1))\n",
    "        pt = torch.exp(-BCE_loss)\n",
    "        F_loss = at*(1-pt)**self.gamma * BCE_loss\n",
    "        return F_loss.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50dc0c86",
   "metadata": {},
   "outputs": [],
   "source": [
    "focal_loss = WeightedFocalLoss(alpha = .05, gamma = 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3b6358f",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model = GCN().to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.01, weight_decay=5e-4)\n",
    "\n",
    "model.train()\n",
    "for epoch in range(200):\n",
    "    print('EPOCH: ', epoch, 'LOSS: ', loss)\n",
    "    optimizer.zero_grad()\n",
    "    out = model(data).squeeze(1)\n",
    "    \n",
    "    #print(out[train_known_mask][0])\n",
    "    loss = focal_loss(out[train_known_mask], data.y[train_known_mask].float())\n",
    "    loss.backward()\n",
    "    optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e693a45",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0932022",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = torch.sigmoid(model(data).squeeze(1))\n",
    "pred = torch.Tensor(np.array([p>=.65 for p in pred]))\n",
    "test_pred = pred[test_known_mask]\n",
    "print(test_pred.sum()/num_test_nodes)\n",
    "test_y = y[test_known_mask]\n",
    "print(test_pred[:10])\n",
    "print(test_y[:10])\n",
    "correct = (test_pred == test_y).sum()\n",
    "acc = int(correct) / num_test_nodes\n",
    "print(f'Accuracy: {acc:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7db96179",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_y = y[test_known_mask]\n",
    "true_pos = test_y.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "694309aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_y_bool = test_y.bool()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b667f153",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_threshs = 100\n",
    "threshs = [i*(1/num_threshs) for i in range(num_threshs)]\n",
    "\n",
    "precisions = {}\n",
    "\n",
    "recalls = {}\n",
    "\n",
    "accs = {}\n",
    "\n",
    "best_acc = 0\n",
    "\n",
    "best_precision = 0\n",
    "\n",
    "for thresh in threshs:\n",
    "    \n",
    "    print('THRESH: ', thresh, 'ACC :', acc, 'PRECISION: ', precision, 'RECALL: ', recall)\n",
    "    \n",
    "    thresh_pred = torch.Tensor(np.array([p>=thresh for p in pred])).bool()\n",
    "    test_pred = thresh_pred[test_known_mask]\n",
    "    pred_pos = test_pred.sum()\n",
    "    correct_pos = (test_pred & test_y_bool).sum()\n",
    "    correct = (test_pred == test_y).sum()\n",
    "    precision = correct_pos/pred_pos\n",
    "    recall = correct_pos/true_pos\n",
    "    acc = int(correct)/num_test_nodes\n",
    "    \n",
    "    if acc > best_acc:\n",
    "        \n",
    "        best_acc = acc\n",
    "        \n",
    "    if precision > best_precision:\n",
    "        \n",
    "        best_precision = precision\n",
    "    \n",
    "    precisions[thresh] = precision\n",
    "    recalls[thresh] = recall\n",
    "    accs[thresh] = acc"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
